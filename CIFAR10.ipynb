{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classificação de imagens com CIFAR-10"
      ],
      "metadata": {
        "id": "JusErZ9c9v6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicia-se conectando com seu Google Drive"
      ],
      "metadata": {
        "id": "FohCJMu99uL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF-TWErKCrkX",
        "outputId": "52b3abef-f136-4ce7-9adf-4d4734af7df4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando joblib para armazenar e recuperar objetos"
      ],
      "metadata": {
        "id": "1DtQz90897dH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5_1OlRq6FGB",
        "outputId": "7daa76dc-0fc5-4ad7-9887-c3f26f41d19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importações da primeira etapa(construção do modelo):"
      ],
      "metadata": {
        "id": "uYcZL4Ys-Nqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # biblioteca para deep learning\n",
        "from tensorflow.keras import datasets, layers, models # importação de datasets, camadas pré-definidas, definição e treino de modelos\n",
        "import keras # api para construção e treinamento do modelo\n",
        "# import psutil\n",
        "import joblib # importação para salvar e carregar modelos\n",
        "# import time\n",
        "import numpy as np # biblioteca para operações com algebra linear"
      ],
      "metadata": {
        "id": "GrUAV7ud6JuE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o dataset CIFAR-10 que tem 60 mil imagens de 32x32 pixels\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data() # o load_data() retorna duas tuplas\n",
        "\n",
        "# ao treinar contendo imagens e labels, os valores dos pixels das imagens de treino e teste são normalizados\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "UbYWmLDr6Jn3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential() # Cria um modelo sequencial, que é uma pilha linear de camadas\n",
        "\n",
        "# Adiciona uma camada convolucional com 64 filtros de tamanho 5x5 com função de ativação ReLU e entrada para imagens 32x32 com 3 canais(RGB)\n",
        "model.add(layers.Conv2D(64, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2))) # Adiciona uma camada de pooling que reduz as dimensões espaciais sobre 2x2 pixels\n",
        "\n",
        "model.add(layers.Conv2D(128, (5, 5), activation='relu')) # Adiciona outra camada convolucional com 128 filtros de tamanho 5x5\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2))) # Adiciona outra camada de pooling que reduz as dimensões pela metade\n",
        "\n",
        "model.add(layers.Conv2D(128, (5, 5), activation='relu')) # Adiciona mais uma camada convolucional com 128 filtros de tamanho 5x5\n",
        "\n",
        "model.add(layers.Flatten()) # Achata a saída da última camada convolucional transformando a matriz em 1D\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu')) # Adiciona uma camada densa (totalmente conectada) com 128 unidades\n",
        "\n",
        "# Adiciona uma camada densa com 10 unidades e função de ativação softmax para calcular a distribuição nas 10 classes\n",
        "model.add(layers.Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "uHYAqkkT6PY-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compila o modelo usando o otimizador adam para ajustar a taxa de aprendizado\n",
        "# É usado 'SparseCategoricalCrossentropy' como função de perda para classificação\n",
        "# Já 'from_logits=True' indica que a função de perda espera saídas como logits(funções lineares) ao invés de probabilidades\n",
        "# Como padrão, usa-se accuracy como métrica pra medir a precisão do modelo durante o treino\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FkTP_Jna6WUf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui se inicia o treinamento do modelo com images e labels que são os dados usados\n",
        "# foi setado que o treino passe 5 vezes pelo conjunto de dados e um tamanho de amostra de 64 antes de passar pelo backpropagation\n",
        "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FokwLkr76Yvf",
        "outputId": "ba3fa0d7-746f-4ec4-ad61-78e745cd29d4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 233s 296ms/step - loss: 1.5480 - accuracy: 0.4332 - val_loss: 1.3074 - val_accuracy: 0.5290\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 252s 323ms/step - loss: 1.2031 - accuracy: 0.5735 - val_loss: 1.1568 - val_accuracy: 0.5976\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 265s 339ms/step - loss: 1.0432 - accuracy: 0.6332 - val_loss: 1.0243 - val_accuracy: 0.6386\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 244s 312ms/step - loss: 0.9256 - accuracy: 0.6748 - val_loss: 1.0374 - val_accuracy: 0.6408\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 253s 324ms/step - loss: 0.8357 - accuracy: 0.7053 - val_loss: 0.9252 - val_accuracy: 0.6779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui é definido uma parada que interrompe caso a loss seja muito ruim\n",
        "# restore_best_weights=True faz com que o modelo retorne aos melhores pesos\n",
        "# start_from_epoch=2 inicia a verificação de parada antecipada a partir da segunda época\n",
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True, start_from_epoch=2)"
      ],
      "metadata": {
        "id": "7Cif2_M_6cch"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5') # Salva o modelo treinado no arquivo model.h5, armazenando pesos, arquitetura e otimizador do modelo"
      ],
      "metadata": {
        "id": "fojre_qaD8pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a020c6c-6075-473c-ec4d-dc8393bf29e4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementação de API usando Flask e Ngrok"
      ],
      "metadata": {
        "id": "s0mr3nGG_oCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação para rodar o ngrok"
      ],
      "metadata": {
        "id": "Noum-A0qAPXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação para o Flask criar tunel público para a aplicação, normalmente usado para ambientes de desenvolvimento que não possuem endereço IP público como é o caso desse modelo desenvolvido neste notebook Colab"
      ],
      "metadata": {
        "id": "ONgzO_fXBFNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sW7XJ4JKdka",
        "outputId": "132f443a-dac6-454b-939c-28abe3a7a8cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação do ngrok"
      ],
      "metadata": {
        "id": "sJ3yeQ6PAMzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67J1agszK6Xe",
        "outputId": "9f6feb2d-ed21-40fc-ceb3-1f68137f7d19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# improtação do ngrok para criar e gerenciar túneis que apontam para serviços para rodar localmente aplicações\n",
        "# os tuneis são encapsulamento de dados privados para que sejam enviados para uma rede pública\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "PfAv_7k_K0xx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atualização do ngrok caso necessário"
      ],
      "metadata": {
        "id": "9cKmYw1eAVqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGfQkJOGsCO8",
        "outputId": "94c3a99d-79f7-4619-ac2b-a70b2826edec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importações necessárias para rodar o Flask"
      ],
      "metadata": {
        "id": "xX6msOu2A20T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify # microframework para criar aplicações web\n",
        "# importação de threads para o flask rodar nessas threads e permitir que células posteriores possam rodar e para que o servidor responda outras requisições\n",
        "from threading import Thread\n",
        "from flask_ngrok import run_with_ngrok # importação para integrar a aplicação flask com o ngrok e iniciar os tuneis\n",
        "from PIL import Image # importação para manipulação de imagens\n",
        "import io # manipula streams de dados binários para imagens em memória"
      ],
      "metadata": {
        "id": "1Y_BrNdNKSxA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caso for necessário e ultrapassar o limite grátis de 3 tuneis rodando disponibilizados pelo ngrok, é necessário desconectar todos os tuneis\n",
        "\n",
        "### Atenção: Rode essa célula apenas se for necessário, como o caso acima"
      ],
      "metadata": {
        "id": "AN2WUSe0CLrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tunnels = ngrok.get_tunnels() # recupera uma lista de todos os túneis ativos\n",
        "\n",
        "# Desconecta cada túnel individualmente\n",
        "for tunnel in tunnels:\n",
        "    ngrok.disconnect(tunnel.public_url)"
      ],
      "metadata": {
        "id": "oW3963HErIFE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conexão com os tuneis do ngrok, com a porta padrão 5000"
      ],
      "metadata": {
        "id": "x2F0YqO6CnI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "http_tunnel = ngrok.connect(5000)  # Conecta um novo túnel à porta 5000 local"
      ],
      "metadata": {
        "id": "Yvur4NnWrXur"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Túnel reaberto:\", http_tunnel.public_url)  # Imprime o URL público do túnel para ser usada futuramente"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCxQmc9Ord9k",
        "outputId": "4947865a-0e6e-41e0-e93e-968466fa1bc5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Túnel reaberto: https://1509-34-105-96-145.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "É importante destacar que antes de fazer a conexão com o ngrok, é preciso efetuar o cadastro no site Ngrok e ter uma conta que terá o token de acesso, este token é disponibilizado no dashboard na opção \"Your Authtoken\", que é onde se tem o token abaixo:"
      ],
      "metadata": {
        "id": "N8i3fJzbrWmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token('2hbscXmCDNgwgyJaAW3tyVOES4C_39ii3MLoEiv5GURCX83RJ') # token de acesso do ngrok para ser possível se conectar ao servidor"
      ],
      "metadata": {
        "id": "T_PH38oLpcNa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tunnels = ngrok.get_tunnels() # obtém uma lista de todos os túneis ngrok ativos"
      ],
      "metadata": {
        "id": "G8DWInYCS21B"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialização da aplicação Flask genérica, o qual carrega o modelo pré-treinado e define uma rota chamada \"predict\" que aceita apenas requsiições POST, visto que é a única que vai ser trabalhada(envio de imagem)"
      ],
      "metadata": {
        "id": "Uf-q3fwBF_AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "# Carrega o modelo\n",
        "model = tf.keras.models.load_model('/content/model.h5')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({'erro': 'Nenhum arquivo'}), 400\n",
        "\n",
        "    # Obtém o arquivo da requisição\n",
        "    file = request.files['file']\n",
        "    if file:\n",
        "        image = Image.open(io.BytesIO(file.read())) # abre imagem\n",
        "        image = image.resize((32, 32)) # redimensiona a imagem no padrão definido como 32x32\n",
        "        image = np.array(image)\n",
        "        image = image / 255.0  # Normalização\n",
        "        image = np.expand_dims(image, axis=0)  # Adiciona dimensão de batch\n",
        "\n",
        "        predictions = model.predict(image) # faz a previsão do modelo\n",
        "        predicted_class = np.argmax(predictions, axis=1)[0]  # Classificação\n",
        "\n",
        "        return jsonify({'predicted_class': str(predicted_class)})\n",
        "\n",
        "# execução\n",
        "def run_flask():\n",
        "    app.run(threaded=True, use_reloader=False, port=5000)\n",
        "\n",
        "# Roda Flask em uma thread separada para permitir a rodagem das próximas células\n",
        "flask_thread = Thread(target=run_flask)\n",
        "flask_thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGw25WqkKM3P",
        "outputId": "4154e51f-e9fe-4278-802c-49e7ce35a36a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação para que seja possível requisições como POST serem feitas"
      ],
      "metadata": {
        "id": "SZk5oA_OFfwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n"
      ],
      "metadata": {
        "id": "n7wW0jJ6S17-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c4ca5a-1e24-4062-83ba-34bf5a6791b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 856, in _parseNoCache\n",
            "    tokens = fn(instring, tokens_start, ret_tokens)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 291, in wrapper\n",
            "    ret = func(*args[limit:])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 71, in <lambda>\n",
            "    lambda s, l, t: Marker(s[t._original_start : t._original_end])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 278, in __init__\n",
            "    self._markers = _coerce_parse_result(MARKER.parseString(marker))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 825, in _parseNoCache\n",
            "    ret_tokens = ParseResults(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 139, in __new__\n",
            "    self = object.__new__(cls)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 137, in updatecache\n",
            "    lines = fp.readlines()\n",
            "  File \"/usr/lib/python3.10/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests # importação para requisições, auxiliando o input de imagens para classificação"
      ],
      "metadata": {
        "id": "7Sj7yr8sUAVO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://1509-34-105-96-145.ngrok-free.app/predict'\n",
        "\n",
        "# Caminho para a imagem a ser enviada\n",
        "image_path = '/content/drive/MyDrive/CIFAR-10/thumb-horse.jpg'\n",
        "\n",
        "# Abre a imagem em modo binário\n",
        "with open(image_path, 'rb') as img:\n",
        "    files = {'file': ('image.jpg', img, 'image/jpeg')}\n",
        "\n",
        "    # Envia a requisição POST\n",
        "    response = requests.post(url, files=files)\n",
        "\n",
        "    # Imprime a resposta da API\n",
        "    print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asO70sz5TEL8",
        "outputId": "15258655-6dd0-4f78-c02a-a1c1253aac4f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [09/Jun/2024 16:27:36] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"predicted_class\":\"7\"}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}